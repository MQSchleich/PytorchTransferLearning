{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComputerVision",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MQSchleich/PytorchTransferLearning/blob/master/ComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymNHR8UX3kYK",
        "colab_type": "text"
      },
      "source": [
        "# Goal\n",
        "The aim is to get a general understanding of transferlearning and check the performance on MNIST. \n",
        "# Requirements\n",
        "For training and predictions you should use a GPU. Only the final layer of the model was trained to see, if the performance gains could achieve good results. If you run into memory problems try running the training and test prediciton in different runs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_oRIXHL4PqH",
        "colab_type": "text"
      },
      "source": [
        "# Model \n",
        "Import model, set parameters and import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8cGwFyJXUzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "## model \n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opoosed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbU11M5o4hCH",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading and Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegtfqsxhSGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with np.load('prediction-challenge-01-data.npz') as fh:\n",
        "    data_x = fh['data_x']\n",
        "    data_y = fh['data_y']\n",
        "    test_x = fh['test_x']\n",
        "    \n",
        "transformed_x = []\n",
        "preprocess_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "for i in range(len(data_x)): \n",
        "  temp_x = np.squeeze(data_x[i])\n",
        "  i=Image.fromarray(temp_x).convert(\"RGB\")\n",
        "  input_tensor = preprocess_train(i)\n",
        "  input_batch = input_tensor.squeeze(0) \n",
        "\n",
        "  transformed_x.append(input_batch)\n",
        "data_x = transformed_x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mQIoXgK4vtg",
        "colab_type": "text"
      },
      "source": [
        "## Check the transformation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQWErW5oQQv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu3qUknX41z5",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHgFpFtZiR8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tensor_x = torch.stack(data_x)\n",
        "tensor_y = torch.Tensor(data_y).long()\n",
        "tensor_y = torch.nn.functional.one_hot(tensor_y, num_classes=10)\n",
        "image_datasets = data.TensorDataset(tensor_x, tensor_y)\n",
        "# transform to torch tensor\n",
        "# create your datset\n",
        "train_len = int(0.9*(len(data_x)))\n",
        "val_len = len(data_y)- train_len\n",
        "train, val = data.random_split(image_datasets, lengths=[train_len, val_len])\n",
        "\n",
        "data_img = {\"train\": train , \"val\":val}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(data_img[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(data_img[x]) for x in ['train', 'val']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfUrBuX5BDw",
        "colab_type": "text"
      },
      "source": [
        "# Set-Up Image Viewer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uplqA7suJGdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy()\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1qqz2X85RbE",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model \n",
        "The output of the model can be adjusted, however if using cross-entropy as a loss function, one has to take care about the dimensions in the for-loop for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kgU8dFYZaPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    _, lab = torch.max(labels, 1)\n",
        "                    loss = criterion(outputs, lab)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == lab)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model, \"modelres50.pt\")\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9n0ZGhfZ2lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hpo8Qvb5uuq",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation of the Model\n",
        "## Data Processing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EZXuXg7Y7Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#load test_set \n",
        "with np.load('prediction-challenge-01-data.npz') as fh:\n",
        "    test_x = fh['test_x']\n",
        "\n",
        "transformed_x = []\n",
        "preprocess_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "for i in range(len(test_x)): \n",
        "  temp_x = np.squeeze(test_x[i])\n",
        "  i=Image.fromarray(temp_x).convert(\"RGB\")\n",
        "  display(i)\n",
        "  input_tensor = preprocess_test(i)\n",
        "  input_batch = input_tensor.squeeze(0) \n",
        "  transformed_x.append(input_batch)\n",
        "\n",
        "test_x = transformed_x\n",
        "display(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1y2joZA6Efw",
        "colab_type": "text"
      },
      "source": [
        "## Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-3FQyVSj8fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "predictions = []\n",
        "model_conv = torch.load(\"modelres50.pt\")\n",
        "print(torch.cuda.is_available())\n",
        "model_conv.eval()\n",
        "for i in range(0, len(test_x), 4):\n",
        "  temp = test_x[i:i+4]\n",
        "  temp = torch.stack(temp)\n",
        "  prediction = (model_conv(temp.cuda()))\n",
        "  _, preds = torch.max(prediction, 1)\n",
        "  predictions.append(preds.cpu().numpy())\n",
        "prediction = np.array(predictions).flatten()\n",
        "# THAT'S YOUR JOB\n",
        "\n",
        "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
        "assert prediction.ndim == 1\n",
        "assert prediction.shape[0] == 2000\n",
        "\n",
        "# AND SAVE EXACTLY AS SHOWN BELOW\n",
        "np.save('prediction.npy', prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEZH0Hs7lKan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}